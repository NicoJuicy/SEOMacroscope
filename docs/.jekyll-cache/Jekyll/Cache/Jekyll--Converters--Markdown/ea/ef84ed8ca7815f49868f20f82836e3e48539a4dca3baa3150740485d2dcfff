I"
<p class="lead">I have been implementing several different methods to try and identify duplicate and near-duplicate content within the set of pages crawled.</p>

<h2 id="simple-etag-and-checksum-logging">Simple ETag and Checksum Logging</h2>

<p>The simplest of these is achieved by recording the ETag HTTP Header, if it’s returned by the remote web server, and identify which of the crawled URLs appear to have the same ETag value.</p>

<p>Similarly, for any documents that SEO Macroscope actually downloads (such as HTML, PDFs, etc…), a checksum value is computed. Different URLs that have the same checksum are a strong indicator that the content is exactly the same.</p>

<h2 id="finding-duplicates-by-levenshtein-edit-distance">Finding duplicates by Levenshtein Edit Distance</h2>

<p>Another technique that I’ve used is <a href="https://en.wikipedia.org/wiki/Levenshtein_distance">Levenshtein Edit Distance</a> measuring; leveraging <a href="https://github.com/DanHarltey/Fastenshtein">Dan Harltey’s Fastenshtein implementation</a>. Currently, SEO Macroscope will only apply this to documents that have body text in them, such as HTML pages and PDFs.</p>

<p>Briefly, what that means is that if you have multiple pages on your site that are very closely similar, but perhaps with a few minor differences, then these may be detected and reported upon. For example, if two pages are very closely similar, but perhaps they were rendered with very slightly different text in them somewhere, then they will not have matching checksums, but they may be similar enough to fall within the Levenshtein Edit Distance threshold that you specify.</p>

<p>A typical example may be an ecommerce site, that presents much the same content under different URL variations.</p>

<p>The only drawback is that this is quite an intensive process if there are a lot of pages on your site; so it may be necessary to restrict spidering to a subset.</p>

<p>The SEO Macroscope preferences includes options to specify the initial similarity of the documents to apply the Levenshtein algorithm to. If documents that fall within the parameters are found, they will be reported.</p>

<h2 id="export-excel-reports">Export Excel Reports</h2>

<p>In all cases, the ETags, checksums, and Levenshtein Edit Distance values can be found by exporting a <strong>Duplicate Content Report</strong> from the Reports menu, after completing a crawl of your website.</p>

<p>Please note that if you have enabled Levenshtein Edit Distance in the preferences, it may take quite some time for the report to be generated.</p>
:ET